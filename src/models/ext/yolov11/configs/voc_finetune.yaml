# Training configuration for fine-tuning YOLOv11 on combined PASCAL VOC

# --- Base Model & Dataset ---
# Base model weights file (YOLOv11 Large)
model: yolo11l.pt
# Path to the dataset definition yaml (relative to project root)
data: src/models/ext/yolov11/configs/voc_detect.yaml

# --- Training Hyperparameters ---
# Number of epochs (adjust as needed)
epochs: 100
# Training image size
imgsz: 640
# Batch size (-1 for auto-batch calculation, or specify e.g., 8, 16 for yolov11l)
# Adjust based on GPU memory (e.g., 16 might work on 2x A5000)
batch: 16
# Number of worker threads for data loading
workers: 8
# Optimizer: 'SGD', 'Adam', 'AdamW', 'NAdam', 'RAdam', 'RMSProp', 'auto'
optimizer: auto
# Initial learning rate (e.g., 0.01 for SGD, 0.001 for AdamW)
lr0: 0.01
# Final learning rate (lr0 * lrf)
lrf: 0.01
# Close mosaic augmentation for the last N epochs (e.g., 10, or 0 to disable)
close_mosaic: 10
# Add other hyperparameters from YOLOv11 docs as needed
# e.g., weight_decay, momentum, warmup_epochs, augmentations (hsv_h, etc.)
# patience: 100

# --- Execution Settings ---
# Device: '' for auto, 'cpu', '0', '0,1'
device: '0,1'
# Pretrained weights (MUST be True for fine-tuning)
pretrained: True

# --- Output Settings ---
# Default project directory (relative to project root, can be overridden by --project CLI arg)
project: runs/detect

# --- Wandb Logging (will be used automatically if logged in) ---
# Set to False to disable wandb even if installed/logged in
# enable_wandb: True