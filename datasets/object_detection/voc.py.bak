"""
Pascal VOC dataset loader for object detection
"""
import torch
from torch.utils.data import Dataset
from torchvision import transforms

from datasets import load_dataset


class PascalVOCDataset(Dataset):
    """
    Pascal VOC dataset for object detection
    
    Uses Huggingface datasets to load Pascal VOC dataset
    """
    
    def __init__(self, split='train', transform=None, download=True):
        """
        Initialize Pascal VOC dataset
        
        Args:
            split: Dataset split ('train', 'val', 'test')
            transform: Optional data augmentation transforms
            download: Whether to download the dataset if not already present
        """
        super().__init__()
        self.split = 'train' if split == 'train' else 'validation'
        self.transform = transform
        
        # Class names for Pascal VOC
        self.class_names = [
            'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',
            'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',
            'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
        ]
        self.num_classes = len(self.class_names)
        
        # Class name to index mapping
        self.class_to_idx = {name: i for i, name in enumerate(self.class_names)}
        
        # Load dataset from Huggingface
        self.dataset = load_dataset('voc', year='2012', split=self.split)
        
        # Default transformations if none provided
        if self.transform is None:
            self.transform = transforms.Compose([
                transforms.Resize((416, 416)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
    
    def __len__(self):
        """Return the number of samples in the dataset"""
        return len(self.dataset)
    
    def __getitem__(self, idx):
        """
        Get a sample from the dataset
        
        Args:
            idx: Index of the sample
        
        Returns:
            dict: Sample containing:
                'image': The image tensor
                'boxes': Bounding boxes in [x, y, w, h] format (normalized 0-1)
                'labels': Class labels
                'image_id': Image ID
        """
        sample = self.dataset[idx]
        
        # Get image
        image = sample['image']
        image_id = sample['image_id']
        width, height = image.size
        
        # Get objects (bounding boxes and labels)
        objects = sample['objects']
        bboxes = objects['bbox']  # [xmin, ymin, xmax, ymax] in absolute coordinates
        labels = objects['category']
        
        # Convert labels to indices
        label_indices = [self.class_to_idx[label] for label in labels]
        
        # Normalize bounding boxes to [0, 1] and convert to [x_center, y_center, width, height]
        normalized_boxes = []
        for bbox in bboxes:
            xmin, ymin, xmax, ymax = bbox
            # Normalize to [0, 1]
            xmin_norm = xmin / width
            ymin_norm = ymin / height
            xmax_norm = xmax / width
            ymax_norm = ymax / height
            
            # Convert to [x_center, y_center, width, height]
            x_center = (xmin_norm + xmax_norm) / 2
            y_center = (ymin_norm + ymax_norm) / 2
            box_width = xmax_norm - xmin_norm
            box_height = ymax_norm - ymin_norm
            
            normalized_boxes.append([x_center, y_center, box_width, box_height])
        
        # Convert to tensor
        boxes = torch.tensor(normalized_boxes, dtype=torch.float32)
        labels = torch.tensor(label_indices, dtype=torch.int64)
        
        # Apply transforms to the image
        if self.transform:
            image = self.transform(image)
        
        return {
            'image': image,
            'boxes': boxes,
            'labels': labels,
            'image_id': image_id
        }
    
    def collate_fn(self, batch):
        """
        Custom collate function for batching samples
        
        Args:
            batch: List of samples
        
        Returns:
            dict: Batched samples
        """
        images = []
        boxes = []
        labels = []
        image_ids = []
        
        for sample in batch:
            images.append(sample['image'])
            boxes.append(sample['boxes'])
            labels.append(sample['labels'])
            image_ids.append(sample['image_id'])
        
        # Stack images into a batch
        images = torch.stack(images, dim=0)
        
        return {
            'images': images,
            'boxes': boxes,
            'labels': labels,
            'image_ids': image_ids
        }         } 