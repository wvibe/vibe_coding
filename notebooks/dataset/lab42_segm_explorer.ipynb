{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9977474c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Exploring the lab42/cov-segm-v3 Dataset\n",
    "\n",
    "This notebook explores the `lab42/cov-segm-v3` dataset from Hugging Face.\n",
    "We will load a few samples, visualize the primary image, parse the `conversations` field,\n",
    "and display the associated mask images, both raw and overlaid on the primary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e27989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf00b29",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Load Dataset\n",
    "\n",
    "Load the validation split, which is smaller and suitable for exploration.\n",
    "We'll examine the first few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f451f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78344818ad374fd09585be5669065034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563fc88ba9ba4934a262810732977186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 samples from lab42/cov-segm-v3\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# Using streaming=True initially can be faster if you only need a few samples,\n",
    "# but for simplicity, we load the first few directly here.\n",
    "DATASET_NAME = \"lab42/cov-segm-v3\"\n",
    "NUM_SAMPLES_TO_LOAD = 3\n",
    "\n",
    "try:\n",
    "    # Load specific samples directly if not streaming\n",
    "    dset = load_dataset(DATASET_NAME, split=f\"validation[:{NUM_SAMPLES_TO_LOAD}]\")\n",
    "    print(f\"Loaded {len(dset)} samples from {DATASET_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load dataset: {e}\")\n",
    "    # Fallback or exit if loading fails\n",
    "    dset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83c60ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_0': None,\n",
       " 'image_1': None,\n",
       " 'image_2': None,\n",
       " 'images_rest': None,\n",
       " 'mask_0': <PIL.PngImagePlugin.PngImageFile image mode=P size=1167x802>,\n",
       " 'mask_1': <PIL.PngImagePlugin.PngImageFile image mode=P size=1167x802>,\n",
       " 'mask_2': <PIL.PngImagePlugin.PngImageFile image mode=P size=1167x802>,\n",
       " 'masks_rest': [<PIL.PngImagePlugin.PngImageFile image mode=P size=1167x802>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=P size=1167x802>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=P size=1167x802>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=P size=1167x802>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=P size=1167x802>],\n",
       " 'conversations': '[{\"phrases\": [{\"id\": 223, \"text\": \"object\", \"type\": \"PhraseType.RDP_PROMPT\"}], \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"instance_masks\": [{\"column\": \"mask_0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 1}, {\"column\": \"mask_0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 2}, {\"column\": \"mask_0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 3}, {\"column\": \"mask_0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 4}, {\"column\": \"mask_0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 5}, {\"column\": \"mask_0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 6}, {\"column\": \"mask_0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 7}, {\"column\": \"mask_0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 8}, {\"column\": \"mask_0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 9}], \"instance_full_masks\": [{\"column\": \"mask_0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 1}, {\"column\": \"mask_0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 2}, {\"column\": \"mask_1\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 1}, {\"column\": \"mask_1\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 2}, {\"column\": \"mask_2\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 1}, {\"column\": \"masks_rest/0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 1}, {\"column\": \"masks_rest/1\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 1}, {\"column\": \"masks_rest/2\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 1}, {\"column\": \"masks_rest/2\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 2}], \"type\": \"ConversationType.SEG_QA\"}, {\"phrases\": [{\"id\": 52, \"text\": \"bin\", \"type\": \"PhraseType.RDP_PROMPT\"}], \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"instance_masks\": [{\"column\": \"mask_0\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 10}], \"instance_full_masks\": [{\"column\": \"masks_rest/3\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 1}], \"type\": \"ConversationType.SEG_QA\"}, {\"phrases\": [{\"id\": 254, \"text\": \"Edge / boundary between individual objects\", \"type\": \"PhraseType.RDP_PROMPT\"}], \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"mask\": {\"column\": \"masks_rest/4\", \"image_uri\": {\"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\", \"format\": \"RGB_8B_HW3\"}, \"positive_value\": 1}, \"type\": \"ConversationType.SEG_QA\"}]',\n",
       " 'id': 'bastian-bastian_weissman-pick-20201012190520-699944',\n",
       " 'dataset': 'cov-segm',\n",
       " 'split': 'validation',\n",
       " 'n_images': 1,\n",
       " 'n_masks': 8,\n",
       " 'n_conversations': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f52738",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Explore Samples\n",
    "\n",
    "Iterate through the loaded samples, displaying their contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62382cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conversations(sample):\n",
    "    conversations_str = sample.get(\"conversations\")\n",
    "    if conversations_str:\n",
    "        try:\n",
    "            parsed_conversations = json.loads(conversations_str)\n",
    "            print(\"Parsed Conversations:\")\n",
    "            # Pretty print the first conversation element for brevity if it exists\n",
    "            if parsed_conversations:\n",
    "                print(json.dumps(parsed_conversations[0], indent=2))\n",
    "                if len(parsed_conversations) > 1:\n",
    "                    print(\n",
    "                        f\"  ... and {len(parsed_conversations) - 1} more conversation elements.\"\n",
    "                    )\n",
    "            else:\n",
    "                print(\"  (Conversations list is empty)\")\n",
    "\n",
    "            # --- Detailed Parsing (Optional Step 7 from Plan) ---\n",
    "            # This section demonstrates extracting info for a specific prompt\n",
    "            print(\"\\n--- Example: Parsing details for each prompt ---\")\n",
    "            for i, conv_item in enumerate(parsed_conversations):\n",
    "                prompts = [p.get(\"text\", \"N/A\") for p in conv_item.get(\"phrases\", [])]\n",
    "                prompt_text = \"; \".join(prompts)\n",
    "                mask_info = conv_item.get(\"mask\")  # Check if 'mask' exists directly\n",
    "\n",
    "                if mask_info:\n",
    "                    mask_col = mask_info.get(\"column\", \"N/A\")\n",
    "                    mask_val = mask_info.get(\"positive_value\", \"N/A\")\n",
    "                    print(\n",
    "                        f\"  Prompt {i}: '{prompt_text}' -> Mask Column: '{mask_col}', Positive Value: {mask_val}\"\n",
    "                    )\n",
    "                else:\n",
    "                    # Might be instance masks or no mask (negative example)\n",
    "                    instance_masks = conv_item.get(\"instance_masks\", [])\n",
    "                    if instance_masks:\n",
    "                        # Handle instance masks if needed - structure is slightly different\n",
    "                        im_details = []\n",
    "                        for im in instance_masks:\n",
    "                            im_col = im.get(\"column\", \"N/A\")\n",
    "                            im_val = im.get(\"positive_value\", \"N/A\")\n",
    "                            im_details.append(f\"Col: {im_col}, Val: {im_val}\")\n",
    "                        print(\n",
    "                            f\"  Prompt {i}: '{prompt_text}' -> Instance Masks: [{'; '.join(im_details)}]\"\n",
    "                        )\n",
    "                    else:\n",
    "                        print(\n",
    "                            f\"  Prompt {i}: '{prompt_text}' -> No direct 'mask' or 'instance_masks' field found.\"\n",
    "                        )\n",
    "            # --- End Optional Step ---\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error parsing conversations JSON.\")\n",
    "            parsed_conversations = None\n",
    "    else:\n",
    "        print(\"conversations field not found or is empty.\")\n",
    "        parsed_conversations = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3436570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_masks(sample, idx):\n",
    "    mask_cols_to_check = [f\"mask_{i}\" for i in range(3)]  # mask_0, mask_1, mask_2\n",
    "\n",
    "    for col_name in mask_cols_to_check:\n",
    "        mask_image = sample.get(col_name)\n",
    "        if mask_image:\n",
    "            mask_np = np.array(mask_image)\n",
    "\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "            # Display raw mask\n",
    "            im0 = axes[0].imshow(mask_np, cmap=\"viridis\")  # Use a distinct colormap\n",
    "            axes[0].set_title(f\"Sample {idx}: Raw {col_name}\")\n",
    "            axes[0].axis(\"off\")\n",
    "            fig.colorbar(\n",
    "                im0, ax=axes[0], fraction=0.046, pad=0.04\n",
    "            )  # Add colorbar to show values\n",
    "\n",
    "            # Display overlay\n",
    "            if image_np is not None:\n",
    "                axes[1].imshow(image_np)\n",
    "                axes[1].imshow(mask_np, cmap=\"viridis\", alpha=0.5)  # Overlay with transparency\n",
    "                axes[1].set_title(f\"Sample {idx}: {col_name} Overlay on image_0\")\n",
    "                axes[1].axis(\"off\")\n",
    "            else:\n",
    "                axes[1].set_title(f\"Sample {idx}: Overlay (image_0 missing)\")\n",
    "                axes[1].axis(\"off\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        # else:\n",
    "        #     print(f\"{col_name} not found or is None in Sample {idx}.\") # Reduce verbosity\n",
    "\n",
    "    # Handle masks_rest (sequence of masks)\n",
    "    masks_rest_list = sample.get(\"masks_rest\")\n",
    "    if masks_rest_list and isinstance(masks_rest_list, list) and len(masks_rest_list) > 0:\n",
    "        print(f\"--- Visualizing masks_rest (found {len(masks_rest_list)}) ---\")\n",
    "        for rest_idx, rest_mask_image in enumerate(masks_rest_list):\n",
    "            if rest_mask_image:\n",
    "                mask_np = np.array(rest_mask_image)\n",
    "                col_name = f\"masks_rest[{rest_idx}]\"\n",
    "\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "                # Display raw mask\n",
    "                im0 = axes[0].imshow(mask_np, cmap=\"viridis\")\n",
    "                axes[0].set_title(f\"Sample {idx}: Raw {col_name}\")\n",
    "                axes[0].axis(\"off\")\n",
    "                fig.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "                # Display overlay\n",
    "                if image_np is not None:\n",
    "                    axes[1].imshow(image_np)\n",
    "                    axes[1].imshow(mask_np, cmap=\"viridis\", alpha=0.5)\n",
    "                    axes[1].set_title(f\"Sample {idx}: {col_name} Overlay on image_0\")\n",
    "                    axes[1].axis(\"off\")\n",
    "                else:\n",
    "                    axes[1].set_title(f\"Sample {idx}: Overlay (image_0 missing)\")\n",
    "                    axes[1].axis(\"off\")\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "    print(f\"--- Finished Sample {idx} ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1af3f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample Index: 0, ID: bastian-bastian_weissman-pick-20201012190520-699944 ---\n",
      "Number of Images reported: 1\n",
      "Number of Masks reported: 8\n",
      "Number of Conversations reported: 3\n",
      "Dataset Source: cov-segm\n",
      "Split: validation\n",
      "image_0 not found in this sample.\n",
      "\n",
      "Available keys in sample: ['image_0', 'image_1', 'image_2', 'images_rest', 'mask_0', 'mask_1', 'mask_2', 'masks_rest', 'conversations', 'id', 'dataset', 'split', 'n_images', 'n_masks', 'n_conversations']\n",
      "Type of 'image_0' field: <class 'NoneType'>\n",
      "image_0 data not found or is empty in this sample.\n",
      "Parsed Conversations:\n",
      "{\n",
      "  \"phrases\": [\n",
      "    {\n",
      "      \"id\": 223,\n",
      "      \"text\": \"object\",\n",
      "      \"type\": \"PhraseType.RDP_PROMPT\"\n",
      "    }\n",
      "  ],\n",
      "  \"image_uri\": {\n",
      "    \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "    \"format\": \"RGB_8B_HW3\"\n",
      "  },\n",
      "  \"instance_masks\": [\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 2\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 3\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 4\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 5\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 6\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 7\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 8\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 9\n",
      "    }\n",
      "  ],\n",
      "  \"instance_full_masks\": [\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 2\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 2\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"masks_rest/0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"masks_rest/1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"masks_rest/2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"masks_rest/2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/621d/621d220cf6435af5af7826d84fcf5a1972bea60b14608b47ea5e01197137ce6b.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 2\n",
      "    }\n",
      "  ],\n",
      "  \"type\": \"ConversationType.SEG_QA\"\n",
      "}\n",
      "  ... and 2 more conversation elements.\n",
      "\n",
      "--- Example: Parsing details for each prompt ---\n",
      "  Prompt 0: 'object' -> Instance Masks: [Col: mask_0, Val: 1; Col: mask_0, Val: 2; Col: mask_0, Val: 3; Col: mask_0, Val: 4; Col: mask_0, Val: 5; Col: mask_0, Val: 6; Col: mask_0, Val: 7; Col: mask_0, Val: 8; Col: mask_0, Val: 9]\n",
      "  Prompt 1: 'bin' -> Instance Masks: [Col: mask_0, Val: 10]\n",
      "  Prompt 2: 'Edge / boundary between individual objects' -> Mask Column: 'masks_rest/4', Positive Value: 1\n",
      "--- Sample Index: 1, ID: knapp-mckesson-default-20200205231500-4007867 ---\n",
      "Number of Images reported: 1\n",
      "Number of Masks reported: 6\n",
      "Number of Conversations reported: 4\n",
      "Dataset Source: cov-segm\n",
      "Split: validation\n",
      "image_0 not found in this sample.\n",
      "\n",
      "Available keys in sample: ['image_0', 'image_1', 'image_2', 'images_rest', 'mask_0', 'mask_1', 'mask_2', 'masks_rest', 'conversations', 'id', 'dataset', 'split', 'n_images', 'n_masks', 'n_conversations']\n",
      "Type of 'image_0' field: <class 'NoneType'>\n",
      "image_0 data not found or is empty in this sample.\n",
      "Parsed Conversations:\n",
      "{\n",
      "  \"phrases\": [\n",
      "    {\n",
      "      \"id\": 223,\n",
      "      \"text\": \"object\",\n",
      "      \"type\": \"PhraseType.RDP_PROMPT\"\n",
      "    }\n",
      "  ],\n",
      "  \"image_uri\": {\n",
      "    \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "    \"format\": \"RGB_8B_HW3\"\n",
      "  },\n",
      "  \"instance_masks\": [\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 2\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 3\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 4\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 5\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 6\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 7\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 8\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 9\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 10\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 11\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 12\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 13\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 14\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 15\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 16\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 17\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 18\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 19\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 20\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 21\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 22\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 23\n",
      "    }\n",
      "  ],\n",
      "  \"instance_full_masks\": [\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 2\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 3\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"masks_rest/0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 7\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 4\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 2\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 3\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"masks_rest/0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 2\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 5\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 13\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 4\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 5\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 6\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"masks_rest/1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 7\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 6\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 7\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 8\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 9\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/8174/817484f1876d08fe1a61accce6a5589a4f631894dd464feece658240195aadbd.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 8\n",
      "    }\n",
      "  ],\n",
      "  \"type\": \"ConversationType.SEG_QA\"\n",
      "}\n",
      "  ... and 3 more conversation elements.\n",
      "\n",
      "--- Example: Parsing details for each prompt ---\n",
      "  Prompt 0: 'object' -> Instance Masks: [Col: mask_0, Val: 1; Col: mask_0, Val: 2; Col: mask_0, Val: 3; Col: mask_0, Val: 4; Col: mask_0, Val: 5; Col: mask_0, Val: 6; Col: mask_0, Val: 7; Col: mask_0, Val: 8; Col: mask_0, Val: 9; Col: mask_0, Val: 10; Col: mask_0, Val: 11; Col: mask_0, Val: 12; Col: mask_0, Val: 13; Col: mask_0, Val: 14; Col: mask_0, Val: 15; Col: mask_0, Val: 16; Col: mask_0, Val: 17; Col: mask_0, Val: 18; Col: mask_0, Val: 19; Col: mask_0, Val: 20; Col: mask_0, Val: 21; Col: mask_0, Val: 22; Col: mask_0, Val: 23]\n",
      "  Prompt 1: 'object that is wrapped in a plastic loose bag' -> No direct 'mask' or 'instance_masks' field found.\n",
      "  Prompt 2: 'barcode on the object' -> Mask Column: 'masks_rest/1', Positive Value: 2\n",
      "  Prompt 3: 'Edge / boundary between individual objects' -> Mask Column: 'masks_rest/2', Positive Value: 1\n",
      "--- Sample Index: 2, ID: knapp-xpo_inhouse-default-20210414124937-3546245 ---\n",
      "Number of Images reported: 1\n",
      "Number of Masks reported: 9\n",
      "Number of Conversations reported: 4\n",
      "Dataset Source: cov-segm\n",
      "Split: validation\n",
      "image_0 not found in this sample.\n",
      "\n",
      "Available keys in sample: ['image_0', 'image_1', 'image_2', 'images_rest', 'mask_0', 'mask_1', 'mask_2', 'masks_rest', 'conversations', 'id', 'dataset', 'split', 'n_images', 'n_masks', 'n_conversations']\n",
      "Type of 'image_0' field: <class 'NoneType'>\n",
      "image_0 data not found or is empty in this sample.\n",
      "Parsed Conversations:\n",
      "{\n",
      "  \"phrases\": [\n",
      "    {\n",
      "      \"id\": 223,\n",
      "      \"text\": \"object\",\n",
      "      \"type\": \"PhraseType.RDP_PROMPT\"\n",
      "    }\n",
      "  ],\n",
      "  \"image_uri\": {\n",
      "    \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "    \"format\": \"RGB_8B_HW3\"\n",
      "  },\n",
      "  \"instance_masks\": [\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 2\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 3\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 4\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 5\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 6\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 7\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 8\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 9\n",
      "    }\n",
      "  ],\n",
      "  \"instance_full_masks\": [\n",
      "    {\n",
      "      \"column\": \"mask_0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"masks_rest/0\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"masks_rest/1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_1\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 2\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"masks_rest/2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"mask_2\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 2\n",
      "    },\n",
      "    {\n",
      "      \"column\": \"masks_rest/3\",\n",
      "      \"image_uri\": {\n",
      "        \"jpg\": \"s3://covariant-datasets-prod/dependencies/covariant-aws-internal-data-us-east-1/coredb/blobs/a418/a418d2f6f0c1fa0965037ef4b6d3be7e7362d2cf2a181a2b25443fb2b63759b7.jpg\",\n",
      "        \"format\": \"RGB_8B_HW3\"\n",
      "      },\n",
      "      \"positive_value\": 1\n",
      "    }\n",
      "  ],\n",
      "  \"type\": \"ConversationType.SEG_QA\"\n",
      "}\n",
      "  ... and 3 more conversation elements.\n",
      "\n",
      "--- Example: Parsing details for each prompt ---\n",
      "  Prompt 0: 'object' -> Instance Masks: [Col: mask_0, Val: 1; Col: mask_0, Val: 2; Col: mask_0, Val: 3; Col: mask_0, Val: 4; Col: mask_0, Val: 5; Col: mask_0, Val: 6; Col: mask_0, Val: 7; Col: mask_0, Val: 8; Col: mask_0, Val: 9]\n",
      "  Prompt 1: 'object that is wrapped in a plastic loose bag' -> Instance Masks: [Col: mask_0, Val: 1; Col: mask_0, Val: 2; Col: mask_0, Val: 3; Col: mask_0, Val: 4; Col: mask_0, Val: 5; Col: mask_0, Val: 6; Col: mask_0, Val: 7; Col: mask_0, Val: 8; Col: mask_0, Val: 9]\n",
      "  Prompt 2: 'bin' -> Instance Masks: [Col: mask_0, Val: 10]\n",
      "  Prompt 3: 'Edge / boundary between individual objects' -> Mask Column: 'masks_rest/5', Positive Value: 1\n"
     ]
    }
   ],
   "source": [
    "if dset:\n",
    "    for idx, sample in enumerate(dset):\n",
    "        print(f\"--- Sample Index: {idx}, ID: {sample['id']} ---\")\n",
    "        print(f\"Number of Images reported: {sample.get('n_images', 'N/A')}\")\n",
    "        print(f\"Number of Masks reported: {sample.get('n_masks', 'N/A')}\")\n",
    "        print(f\"Number of Conversations reported: {sample.get('n_conversations', 'N/A')}\")\n",
    "        print(f\"Dataset Source: {sample.get('dataset', 'N/A')}\")\n",
    "        print(f\"Split: {sample.get('split', 'N/A')}\")\n",
    "\n",
    "        primary_image = sample.get(\"image_0\")\n",
    "        if primary_image:\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(primary_image)\n",
    "            plt.title(f\"Sample {idx}: image_0\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            # Convert to numpy for potential overlay later\n",
    "            image_np = np.array(primary_image)\n",
    "        else:\n",
    "            print(\"image_0 not found in this sample.\")\n",
    "            image_np = None  # Ensure image_np is defined\n",
    "\n",
    "        # --- Inspect the sample structure ---\n",
    "        print(f\"\\nAvailable keys in sample: {list(sample.keys())}\")\n",
    "        if 'image_0' in sample:\n",
    "            # Check the type to understand how the image is stored\n",
    "            print(f\"Type of 'image_0' field: {type(sample['image_0'])}\")\n",
    "            # If it's bytes or dict, you might need specific decoding\n",
    "            if isinstance(sample['image_0'], dict) and 'bytes' in sample['image_0']:\n",
    "                 print(\"   -> 'image_0' seems to be a dict containing bytes.\")\n",
    "            elif isinstance(sample['image_0'], bytes):\n",
    "                 print(\"   -> 'image_0' seems to be raw bytes.\")\n",
    "        else:\n",
    "            print(\"\\n'image_0' key not found in sample.\")\n",
    "        # --- End inspection ---\n",
    "\n",
    "\n",
    "        # %% [markdown]\n",
    "        \"\"\"\n",
    "        ### Image Visualization\n",
    "\n",
    "        Display the primary image (`image_0`). Other `image_*` columns might exist\n",
    "        for different camera views or data types, but `image_0` is typically the main one.\n",
    "        We might need to decode it first based on its type printed above.\n",
    "        \"\"\"\n",
    "\n",
    "        # %%\n",
    "        image_data = sample.get(\"image_0\") # Get the data first\n",
    "        primary_image_pil = None # Initialize PIL image variable\n",
    "\n",
    "        if image_data:\n",
    "            # Attempt to load image data into a PIL Image object\n",
    "            try:\n",
    "                if isinstance(image_data, Image.Image):\n",
    "                    # Already a PIL image\n",
    "                    primary_image_pil = image_data\n",
    "                elif isinstance(image_data, dict) and 'bytes' in image_data and image_data['bytes']:\n",
    "                    # If it's a dict with bytes key\n",
    "                    primary_image_pil = Image.open(io.BytesIO(image_data['bytes']))\n",
    "                elif isinstance(image_data, bytes):\n",
    "                     # If it's raw bytes\n",
    "                     primary_image_pil = Image.open(io.BytesIO(image_data))\n",
    "                else:\n",
    "                    print(f\"Cannot automatically display image_0 of type: {type(image_data)}. Manual handling needed.\")\n",
    "\n",
    "                if primary_image_pil:\n",
    "                    plt.figure(figsize=(6, 6))\n",
    "                    plt.imshow(primary_image_pil)\n",
    "                    plt.title(f\"Sample {idx}: image_0\")\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.show()\n",
    "                    # Convert to numpy for potential overlay later\n",
    "                    image_np = np.array(primary_image_pil)\n",
    "                else:\n",
    "                     image_np = None # Ensure image_np is defined if loading failed\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing or displaying image_0: {e}\")\n",
    "                image_np = None # Ensure image_np is defined on error\n",
    "        else:\n",
    "            print(\"image_0 data not found or is empty in this sample.\")\n",
    "            image_np = None  # Ensure image_np is defined\n",
    "\n",
    "        parse_conversations(sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a1cd8",
   "metadata": {},
   "source": [
    "        ### Basic Metadata\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a76a4f",
   "metadata": {},
   "source": [
    "        ### Image Visualization\n",
    "\n",
    "        Display the primary image (`image_0`). Other `image_*` columns might exist\n",
    "        for different camera views or data types, but `image_0` is typically the main one.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2a74b",
   "metadata": {},
   "source": [
    "        ### Parse `conversations` Field\n",
    "\n",
    "        The `conversations` field is a JSON string containing a list of dictionaries.\n",
    "        Each dictionary links a text prompt to its corresponding mask information (which mask column and which pixel value).\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae78fb",
   "metadata": {},
   "source": [
    "        ### Mask Visualization\n",
    "\n",
    "        Display the raw mask images (`mask_0`, `mask_1`, `mask_2`, `masks_rest`)\n",
    "        and overlay them onto `image_0`. Note that these are the 'packed' masks.\n",
    "        To see the mask for a *specific* prompt, you need to parse the `conversations`\n",
    "        field (as shown above) to find the correct column and pixel value, then filter the NumPy array.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f935ed",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "End of exploration for the first few samples. You can increase `NUM_SAMPLES_TO_LOAD`\n",
    "or use different indices in `.select()` to explore further. Remember that visualizing\n",
    "the mask for a specific *prompt* requires parsing `conversations` to get the mask\n",
    "column and `positive_value`, then filtering the corresponding mask NumPy array."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "vbl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
